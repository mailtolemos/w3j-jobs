const axios = require('axios');
const cheerio = require('cheerio');
const puppeteer = require('puppeteer');
const crypto = require('crypto');

class GenericScraper {
  constructor() {
    this.browser = null;
  }

  async initBrowser() {
    if (!this.browser) {
      this.browser = await puppeteer.launch({
        headless: 'new',
        args: ['--no-sandbox', '--disable-setuid-sandbox']
      });
    }
    return this.browser;
  }

  async closeBrowser() {
    if (this.browser) {
      await this.browser.close();
      this.browser = null;
    }
  }

  generateUniqueId(title, company, url) {
    const data = `${title}-${company}-${url}`;
    return crypto.createHash('md5').update(data).digest('hex');
  }

  cleanText(text) {
    if (!text) return '';
    return text.trim().replace(/\s+/g, ' ');
  }

  async scrapeWithCheerio(source) {
    try {
      const response = await axios.get(source.url, {
        headers: {
          'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        },
        timeout: 15000
      });

      const $ = cheerio.load(response.data);
      const jobs = [];

      if (!source.selectors || !source.selectors.jobContainer) {
        console.log('No selectors configured for', source.name);
        return jobs;
      }

      $(source.selectors.jobContainer).each((index, element) => {
        try {
          const $el = $(element);
          
          const title = this.cleanText($el.find(source.selectors.title).text());
          const company = this.cleanText($el.find(source.selectors.company).text()) || 'Unknown';
          const location = this.cleanText($el.find(source.selectors.location).text()) || 'Remote';
          const salary = this.cleanText($el.find(source.selectors.salary).text()) || 'Not specified';
          
          let link = $el.find(source.selectors.link).attr('href');
          if (link && !link.startsWith('http')) {
            const baseUrl = new URL(source.url);
            link = new URL(link, baseUrl.origin).href;
          }

          const description = this.cleanText($el.find(source.selectors.description).text());

          if (title && link) {
            jobs.push({
              title,
              company,
              location,
              salary,
              description,
              applyUrl: link,
              source: source.name,
              sourceUrl: source.url,
              uniqueId: this.generateUniqueId(title, company, link)
            });
          }
        } catch (err) {
          console.error('Error parsing job element:', err.message);
        }
      });

      return jobs;
    } catch (error) {
      console.error(`Error scraping ${source.name} with Cheerio:`, error.message);
      return [];
    }
  }

  async scrapeWithPuppeteer(source) {
    let page;
    try {
      await this.initBrowser();
      page = await this.browser.newPage();
      
      await page.setUserAgent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36');
      await page.goto(source.url, { waitUntil: 'networkidle2', timeout: 30000 });
      
      // Wait for job listings to load
      if (source.selectors && source.selectors.jobContainer) {
        await page.waitForSelector(source.selectors.jobContainer, { timeout: 10000 }).catch(() => {});
      }

      const jobs = await page.evaluate((selectors, sourceName, sourceUrl) => {
        const jobElements = document.querySelectorAll(selectors.jobContainer);
        const results = [];

        jobElements.forEach(element => {
          try {
            const title = element.querySelector(selectors.title)?.textContent?.trim();
            const company = element.querySelector(selectors.company)?.textContent?.trim() || 'Unknown';
            const location = element.querySelector(selectors.location)?.textContent?.trim() || 'Remote';
            const salary = element.querySelector(selectors.salary)?.textContent?.trim() || 'Not specified';
            const linkElement = element.querySelector(selectors.link);
            let link = linkElement?.href || linkElement?.getAttribute('href');
            const description = element.querySelector(selectors.description)?.textContent?.trim() || '';

            if (title && link) {
              results.push({
                title,
                company,
                location,
                salary,
                description,
                applyUrl: link,
                source: sourceName,
                sourceUrl: sourceUrl
              });
            }
          } catch (err) {
            console.error('Error parsing element:', err);
          }
        });

        return results;
      }, source.selectors, source.name, source.url);

      // Add unique IDs
      jobs.forEach(job => {
        job.uniqueId = this.generateUniqueId(job.title, job.company, job.applyUrl);
      });

      await page.close();
      return jobs;
    } catch (error) {
      if (page) await page.close().catch(() => {});
      console.error(`Error scraping ${source.name} with Puppeteer:`, error.message);
      return [];
    }
  }

  async scrape(source) {
    console.log(`Starting scrape for ${source.name}...`);
    
    // Try Cheerio first (faster), fallback to Puppeteer if needed
    let jobs = await this.scrapeWithCheerio(source);
    
    if (jobs.length === 0) {
      console.log(`Cheerio found 0 jobs, trying Puppeteer for ${source.name}...`);
      jobs = await this.scrapeWithPuppeteer(source);
    }

    console.log(`Found ${jobs.length} jobs from ${source.name}`);
    return jobs;
  }
}

module.exports = new GenericScraper();
